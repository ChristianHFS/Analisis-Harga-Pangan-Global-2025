## Analisis Harga Pangan Global 2025 ğŸŒ¾ğŸ“Š
Repositori ini berisi proyek akhir (Final Project) untuk program CODA RMT-012. Proyek ini berfokus pada pembangunan sistem End-to-End Data Engineering untuk menganalisis dinamika harga komoditas pangan global pada tahun 2025, mengintegrasikan data ekonomi (GDP), dan menyediakan wawasan berbasis data untuk pengambilan keputusan strategis.

## Daftar Isi ğŸ—’ï¸
Project Overview
1. Latar Belakang Masalah
2. Arsitektur & Teknologi
3. Proses ETL
4. Struktur File
5. Cara Menggunakan
6. Dependencies & Libraries
7. Author

## Project Overview ğŸ“
Proyek ini menggunakan dataset dari WFP (World Food Programme) yang bersifat granular. Kami mengintegrasikan data harga pangan dengan indikator ekonomi seperti GDP per kapita untuk memahami hubungan antara daya beli masyarakat dan fluktuasi harga pasar. Data diproses menggunakan arsitektur modern yang mengutamakan skalabilitas dan efisiensi biaya.
Tahapan Utama:
Exploratory Data Analysis (EDA): Pembersihan data dan pemetaan negara menggunakan CountryISO3.
Data Transformation: Pemodelan data menjadi Star Schema untuk kebutuhan Data Warehouse.
Automated Pipeline: Orkestrasi data menggunakan Airflow dan pemrosesan batch dengan PySpark.

## Latar Belakang Masalah ğŸ§
Bagaimana cara memahami dinamika harga komoditas global yang fluktuatif? Masalah utama yang diselesaikan adalah:
Mengidentifikasi tren harga antar wilayah.
Menganalisis ketimpangan harga pangan dibanding kondisi ekonomi (GDP).
Memberikan rekomendasi operasional yang efisien (seperti waktu restok komoditas) berbasis data.

## Arsitektur & Teknologi âš™ï¸
Kami menggunakan Arsitektur Modern Hemat Biaya:
Pemrosesan Data: Apache Spark (PySpark) untuk performa tinggi.
Orkestrasi: Apache Airflow untuk manajemen workflow.
Database: Neon PostgreSQL sebagai Cloud Data Warehouse.
Containerization: Docker untuk konsistensi lingkungan pengembangan.

## Proses ETL ğŸš€
1. Extract
Mengambil data mentah (CSV) secara otomatis dari WFP Humanitarian Data Portal menggunakan protokol HTTP/API.

2. Transform
Cleaning: Menghapus HXL Metadata dan menangani missing values.
Modeling: Memecah data menjadi Fact Table (fact_food_price) dan Dimension Tables (dim_commodity, dim_country, dim_market, dim_date).
Storage: Data disimpan sementara dalam format Parquet untuk efisiensi.

3. Load
Data dimuat ke dalam Neon PostgreSQL menggunakan Spark JDBC, siap untuk dikonsumsi oleh alat visualisasi seperti Tableau atau Power BI.

## Struktur File ğŸ“‚
airflow-with-spark/: Berisi konfigurasi DAGs dan docker-compose untuk pipeline.
Dashboard/: File terkait visualisasi hasil analisis.
EDA/: Notebook analisis awal data harga pangan.
final_project_analysis.ipynb: Analisis utama dan pemodelan data.
final_project.sql: Skema database PostgreSQL (DDL).
datamodelling.png: Diagram skema tabel (Star Schema).

## Cara Menggunakan ğŸ’»
Persiapan Database: Setup database di Neon PostgreSQL dan masukkan kredensial ke file konfigurasi.
Environment: Pastikan Docker terinstal. Jalankan docker-compose up di folder airflow-with-spark.
Running Pipeline: Aktifkan DAG di dashboard Airflow untuk memulai proses ETL.
Analysis: Buka final_project_analysis.ipynb untuk melihat hasil pengolahan data.

## Dependencies & Libraries ğŸ“š
https://github.com/argyadiva/demo-airflow_with_spark

## Author âœï¸
Christian & tim (Raina, Putrima, Owen, Raihan)
